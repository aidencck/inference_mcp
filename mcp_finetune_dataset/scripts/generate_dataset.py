#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”ŸæˆMCPå·¥å…·è°ƒç”¨è®­ç»ƒæ•°æ®é›†
"""

import json
import random
import sys
import os
from typing import List, Dict, Any

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from examples.mcp_tools import tool_registry

class MCPDatasetGenerator:
    """MCPæ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.system_prompt = "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ­£ç¡®è°ƒç”¨MCPå·¥å…·çš„AIåŠ©æ‰‹ã€‚å½“ç”¨æˆ·éœ€è¦è·å–ä¿¡æ¯æˆ–æ‰§è¡Œæ“ä½œæ—¶ï¼Œä½ åº”è¯¥é€‰æ‹©åˆé€‚çš„MCPå·¥å…·å¹¶æ­£ç¡®è°ƒç”¨ã€‚"
        
        # å®šä¹‰å„ç§ç”¨æˆ·è¯·æ±‚æ¨¡æ¿
        self.request_templates = {
            "web_search": [
                "è¯·å¸®æˆ‘æœç´¢å…³äº{topic}çš„ä¿¡æ¯",
                "æˆ‘æƒ³äº†è§£{topic}çš„æœ€æ–°åŠ¨æ€",
                "æœç´¢ä¸€ä¸‹{topic}ç›¸å…³å†…å®¹",
                "æŸ¥æ‰¾{topic}çš„èµ„æ–™"
            ],
            "get_weather": [
                "è¯·å¸®æˆ‘æŸ¥çœ‹{city}çš„å¤©æ°”",
                "æˆ‘æƒ³çŸ¥é“{city}ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
                "è·å–{city}çš„å¤©æ°”ä¿¡æ¯",
                "{city}çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"
            ],
            "list_files": [
                "è¯·å¸®æˆ‘æŸ¥çœ‹{path}ç›®å½•ä¸‹çš„æ–‡ä»¶",
                "åˆ—å‡º{path}ä¸­çš„æ‰€æœ‰æ–‡ä»¶",
                "æ˜¾ç¤º{path}ç›®å½•å†…å®¹",
                "æˆ‘æƒ³çœ‹çœ‹{path}é‡Œæœ‰ä»€ä¹ˆæ–‡ä»¶"
            ],
            "write_file": [
                "è¯·å¸®æˆ‘åˆ›å»ºä¸€ä¸ªåä¸º{filename}çš„æ–‡ä»¶ï¼Œå†…å®¹æ˜¯{content}",
                "å†™å…¥æ–‡ä»¶{filename}ï¼Œå†…å®¹ï¼š{content}",
                "åˆ›å»ºæ–‡ä»¶{filename}å¹¶å†™å…¥ï¼š{content}"
            ],
            "calculate": [
                "è¯·å¸®æˆ‘è®¡ç®—{expression}",
                "è®¡ç®—ä¸€ä¸‹{expression}çš„ç»“æœ",
                "{expression}ç­‰äºå¤šå°‘ï¼Ÿ",
                "å¸®æˆ‘ç®—ç®—{expression}"
            ]
        }
        
        # ç¤ºä¾‹æ•°æ®
        self.example_data = {
            "topics": ["Pythonæœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½å‘å±•", "åŒºå—é“¾æŠ€æœ¯", "äº‘è®¡ç®—", "å¤§æ•°æ®åˆ†æ"],
            "cities": ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·"],
            "paths": ["./", "./data", "./models", "./scripts", "./docs"],
            "filenames": ["test.txt", "data.json", "config.yaml", "readme.md", "script.py"],
            "contents": ["Hello World", "è¿™æ˜¯æµ‹è¯•å†…å®¹", "é…ç½®ä¿¡æ¯", "é¡¹ç›®è¯´æ˜", "print('Hello')"],
            "expressions": ["125 * 37", "256 + 128", "1024 / 8", "15 * 15", "100 - 25"]
        }
    
    def generate_conversation(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªå¯¹è¯æ ·æœ¬"""
        
        # ç”Ÿæˆç”¨æˆ·è¯·æ±‚
        template = random.choice(self.request_templates[tool_name])
        user_message = template.format(**params)
        
        # ç”ŸæˆåŠ©æ‰‹å“åº”ï¼ˆå·¥å…·è°ƒç”¨å‰ï¼‰
        assistant_intro = f"æˆ‘æ¥å¸®æ‚¨{self._get_action_description(tool_name, params)}ã€‚"
        
        # ç”Ÿæˆå·¥å…·è°ƒç”¨
        tool_call = {
            "id": f"call_{random.randint(1000, 9999)}",
            "type": "function",
            "function": {
                "name": tool_name,
                "arguments": json.dumps(params, ensure_ascii=False)
            }
        }
        
        # æ‰§è¡Œå·¥å…·è·å–ç»“æœ
        tool_result = tool_registry.execute_tool(tool_name, **params)
        
        # ç”Ÿæˆæœ€ç»ˆåŠ©æ‰‹å“åº”
        final_response = self._generate_final_response(tool_name, params, tool_result)
        
        # æ„å»ºå®Œæ•´å¯¹è¯
        conversation = {
            "messages": [
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                },
                {
                    "role": "assistant",
                    "content": assistant_intro,
                    "tool_calls": [tool_call]
                },
                {
                    "role": "tool",
                    "tool_call_id": tool_call["id"],
                    "content": tool_result
                },
                {
                    "role": "assistant",
                    "content": final_response
                }
            ]
        }
        
        return conversation
    
    def _get_action_description(self, tool_name: str, params: Dict[str, Any]) -> str:
        """è·å–åŠ¨ä½œæè¿°"""
        descriptions = {
            "web_search": f"æœç´¢å…³äº{params.get('query', '')}çš„ä¿¡æ¯",
            "get_weather": f"è·å–{params.get('city', '')}çš„å¤©æ°”ä¿¡æ¯",
            "list_files": f"æŸ¥çœ‹{params.get('path', '')}ç›®å½•ä¸‹çš„æ–‡ä»¶",
            "write_file": f"åˆ›å»º{params.get('filename', '')}æ–‡ä»¶",
            "calculate": f"è®¡ç®—{params.get('expression', '')}çš„ç»“æœ"
        }
        return descriptions.get(tool_name, "å¤„ç†æ‚¨çš„è¯·æ±‚")
    
    def _generate_final_response(self, tool_name: str, params: Dict[str, Any], tool_result: str) -> str:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        if tool_name == "web_search":
            return f"æ ¹æ®æœç´¢ç»“æœï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†å…³äº{params['query']}çš„ç›¸å…³ä¿¡æ¯ï¼š\n\n{tool_result}\n\nå¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰å¸®åŠ©ï¼"
        elif tool_name == "get_weather":
            return f"{params['city']}çš„å¤©æ°”ä¿¡æ¯å¦‚ä¸‹ï¼š\n\n{tool_result}\n\nè¯·æ ¹æ®å¤©æ°”æƒ…å†µåˆç†å®‰æ’å‡ºè¡Œã€‚"
        elif tool_name == "list_files":
            return f"{params['path']}ç›®å½•çš„å†…å®¹ï¼š\n\n{tool_result}\n\næ‚¨éœ€è¦å¯¹å“ªä¸ªæ–‡ä»¶è¿›è¡Œæ“ä½œå—ï¼Ÿ"
        elif tool_name == "write_file":
            return f"âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼\n\nğŸ“„ **æ–‡ä»¶å**ï¼š{params['filename']}\nğŸ“ **å†…å®¹**ï¼š{params['content']}\n\næ–‡ä»¶å·²ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸­ã€‚"
        elif tool_name == "calculate":
            return f"ğŸ§® **è®¡ç®—ç»“æœ**ï¼š\n\n{tool_result}\n\nè®¡ç®—å®Œæˆï¼"
        else:
            return f"æ“ä½œå®Œæˆï¼š\n\n{tool_result}"
    
    def generate_dataset(self, num_samples: int = 100) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå®Œæ•´æ•°æ®é›†"""
        dataset = []
        
        tools_and_params = [
            ("web_search", lambda: {"query": random.choice(self.example_data["topics"])}),
            ("get_weather", lambda: {"city": random.choice(self.example_data["cities"])}),
            ("list_files", lambda: {"path": random.choice(self.example_data["paths"])}),
            ("write_file", lambda: {
                "filename": random.choice(self.example_data["filenames"]),
                "content": random.choice(self.example_data["contents"])
            }),
            ("calculate", lambda: {"expression": random.choice(self.example_data["expressions"])})
        ]
        
        for i in range(num_samples):
            tool_name, param_generator = random.choice(tools_and_params)
            params = param_generator()
            
            conversation = self.generate_conversation(tool_name, params)
            dataset.append(conversation)
        
        return dataset
    
    def save_dataset(self, dataset: List[Dict[str, Any]], output_path: str):
        """ä¿å­˜æ•°æ®é›†åˆ°JSONLæ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in dataset:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")
        print(f"æ€»æ ·æœ¬æ•°: {len(dataset)}")

if __name__ == "__main__":
    import argparse
    import yaml
    import os
    
    parser = argparse.ArgumentParser(description="ç”ŸæˆMCPè®­ç»ƒæ•°æ®é›†")
    parser.add_argument("--config", type=str, default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--train_samples", type=int, help="è®­ç»ƒæ ·æœ¬æ•°é‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--val_samples", type=int, help="éªŒè¯æ ·æœ¬æ•°é‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    
    # ç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®
    config_path = args.config
    if not os.path.isabs(config_path):
        config_path = os.path.join(project_dir, config_path)
    
    if not os.path.exists(config_path):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        exit(1)
    
    print(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # è·å–æ•°æ®é…ç½®
    data_config = config.get('data', {})
    train_samples = args.train_samples or data_config.get('num_train_samples', 500)
    val_samples = args.val_samples or data_config.get('num_val_samples', 100)
    
    # è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„
    train_file = data_config.get('train_file', './data/mcp_tool_calls.jsonl')
    val_file = data_config.get('validation_file', './data/mcp_validation.jsonl')
    
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
    if not os.path.isabs(train_file):
        train_file = os.path.join(project_dir, train_file)
    if not os.path.isabs(val_file):
        val_file = os.path.join(project_dir, val_file)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(train_file), exist_ok=True)
    os.makedirs(os.path.dirname(val_file), exist_ok=True)
    
    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generator = MCPDatasetGenerator()
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®é›†
    train_dataset = generator.generate_dataset(num_samples=train_samples)
    generator.save_dataset(train_dataset, train_file)
    
    # ç”ŸæˆéªŒè¯æ•°æ®é›†
    val_dataset = generator.generate_dataset(num_samples=val_samples)
    generator.save_dataset(val_dataset, val_file)
    
    print("æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"è®­ç»ƒæ•°æ®: {train_file}")
    print(f"éªŒè¯æ•°æ®: {val_file}")